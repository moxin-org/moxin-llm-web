---
import Layout from '~/layouts/PageLayout.astro';

import Hero from '~/components/widgets/Hero.astro';
import Note from '~/components/widgets/Note.astro';
import Features from '~/components/widgets/Features.astro';
import Steps from '~/components/widgets/Steps.astro';
import Content from '~/components/widgets/Content.astro';
import FAQs from '~/components/widgets/FAQs.astro';
import Stats from '~/components/widgets/Stats.astro';
import CallToAction from '~/components/widgets/CallToAction.astro';

const metadata = {
  title: 'Moxin LLM | Truly Open, Fully Reproducible AI',
  ignoreTitleTemplate: true,
};
---

<Layout metadata={metadata}>
  <Hero
  actions={[
    {
      variant: 'primary',
      text: 'Get on Hugging Face',
      href: 'https://huggingface.co/moxin-org',
      target: '_blank',
      icon: 'tabler:download',
    },
    { 
      text: 'Read Paper', 
      href: 'https://arxiv.org/abs/2412.06845',
      target: '_blank' 
    },
  ]}
  image={{ src: '~/assets/images/hero-image.png', alt: 'Moxin LLM Hero Image' }}
>
    <Fragment slot="title">
      Moxin LLM <br>Truly <span class="text-accent dark:text-white"> Open</span>, Fully <span class="text-accent dark:text-white"> Reproducible</span>
    </Fragment>

    <Fragment slot="subtitle">
      <span class="hidden sm:inline">
        <span class="font-semibold">Moxin LLM</span> is a high-performance language model.
      </span>
      <span class="block mb-1 sm:hidden font-bold text-blue-600">Moxin LLM: Open & Reproducible.</span>
      Achieving SOTA performance on Zero-shot tasks, it is designed for efficiency, especially on edge devices.
    </Fragment>
  </Hero>


  <Note title="Moxin LLM Core Philosophy:" description="Truly Open, Fully Reproducible, High-Performance AI." />

  <Features
    id="features"
    tagline="Key Features"
    title="Why Choose Moxin LLM?"
    subtitle="Discover the advantages of Moxin LLM, designed for developers and researchers seeking a transparent and powerful language model."
    items={[
      {
        title: 'Thorough Openness & Reproducibility',
        description:
          'We provide model weights, training data details, and scripts, ensuring transparency and enabling deep research and customization.',
        icon: 'tabler:database-search',
      },
      {
        title: 'SOTA-level Performance',
        description:
          'Achieves state-of-the-art results on multiple Zero-shot benchmarks, comparable to leading models like DeepSeek.',
        icon: 'tabler:rocket',
      },
      {
        title: 'Powerful Engine for Edge AI',
        description:
          'Moxin LLM aims to be a leader in open-source edge language models, comparable to Phi and Gemma, with superior reproducibility.',
        icon: 'tabler:device-mobile-code',
      },
      {
        title: 'Advanced Technology Stack',
        description:
          'Utilizes GPRO enhanced learning and a Tokenizer MOE architecture for improved performance and efficiency.',
        icon: 'tabler:brain',
      },
      {
        title: 'Seamless OminiX Integration',
        description:
          'Works with the self-developed OminiX inference and fine-tuning engine for optimal performance on various edge hardware, including domestic NPUs.',
        icon: 'tabler:settings-cog',
      },
      {
        title: 'Data Transparency & Customizability',
        description:
          'Access to model weights, training data composition, and scripts allows for efficient fine-tuning for specific applications like robotics or translation.',
        icon: 'tabler:adjustments-horizontal',
      },
    ]}
  />



  <Content
    isAfterContent
    tagline="Application Potential"
    title="Unlocking New Possibilities with Moxin LLM"
    items={[
      {
        title: 'Robotics Command Fine-tuning',
        description: `Leverage data transparency to efficiently fine-tune Moxin LLM for specific robotics instructions and applications.`,
      },
      {
        title: 'Professional Translation',
        description:
          'Customize the model with specialized terminology for high-quality, domain-specific translation tasks.',
      },
      {
        title: 'Edge AI Innovations',
        description:
          "Power AI applications directly on devices like mobile phones and personal computers, ensuring privacy and low latency.",
      },
      {
        title: 'Research and Development',
        description:
          'The open and reproducible nature of Moxin LLM makes it an ideal platform for academic research and exploring new frontiers in AI.',
      },
    ]}
    image={{
      src: 'https://images.unsplash.com/photo-1600132806370-bf17e65e942f?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2194&q=80',
      alt: 'Moxin LLM Application Examples Concept',
    }}
  >
    <Fragment slot="content">Moxin LLM's flexibility opens doors to a wide range of innovative uses.</Fragment>

    <Fragment slot="bg">
      <div class="absolute inset-0 bg-blue-50 dark:bg-transparent"></div>
    </Fragment>
  </Content>

  <Content
  isReversed
  tagline="Moxin Ecosystem"
  title="The Moxin Personal AI Stack"
  items={[
    {
      title: 'Moxin LLM: The Core Model',
      description:
        'A high-performance, truly open, and fully reproducible language model at the heart of the ecosystem.',
    },
    {
      title: 'MoFa: Intelligent Agent Framework',
      description:
        'Leverages the capabilities of Moxin LLM to build intelligent agents.',
    },
    {
      title: 'Moly: Rust LLM Client',
      description:
        'Developer tools, including a Rust LLM client, for interacting with the Moxin ecosystem.',
    },
    {
      title: 'OminiX: Edge Inference & Fine-tuning Engine',
      description:
        'Ensures Moxin LLM runs efficiently on edge devices with optimized performance.',
    },
  ]}
  image={{
    src: 'https://images.unsplash.com/photo-1519389950473-47ba0277781c?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2070&q=80',
    alt: 'Moxin Personal AI Stack Concept Image',
  }}
>
  <Fragment slot="content">
    <h3 class="text-2xl font-bold tracking-tight dark:text-white sm:text-3xl mb-2">A Comprehensive AI Ecosystem</h3>
    Moxin LLM, together with MoFa, Moly, and OminiX, forms the Moxin Personal AI Stack, aiming to build a strong contributor community.
  </Fragment>

  <Fragment slot="bg">
    <div class="absolute inset-0 bg-blue-50 dark:bg-transparent"></div>
  </Fragment>
</Content>

  <Steps
    title="Get Started with Moxin LLM."
    items={[
      {
        title: 'Step 1: <span class="font-medium">Explore Models</span>',
        description:
          "Visit our Hugging Face page to discover Moxin LLM models like Moxin-7B-Base, Chat, Instruct, and Reasoning.",
        icon: 'tabler:atom-2',
      },
      {
        title: 'Step 2: <span class="font-medium">Access Resources</span>',
        description:
          "Check out our GitHub repository for technical reports, scripts, and guides on how to use and fine-tune Moxin LLM.",
        icon: 'tabler:files',
      },
      {
        title: 'Step 3: <span class="font-medium">Deploy with OminiX</span>',
        description:
          'Utilize the OminiX engine for optimal performance when deploying Moxin LLM on your edge devices.',
        icon: 'tabler:player-play',
      },
      {
        title: 'Ready to Innovate!',
        description: 'Start building your AI applications with a truly open and reproducible LLM.',
        icon: 'tabler:check',
      },
    ]}
    image={{
      src: 'https://images.unsplash.com/photo-1616198814651-e71f960c3180?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=987&q=80',
      alt: 'Steps to use Moxin LLM Concept Image',
    }}
  />

  <FAQs
    title="Frequently Asked Questions about Moxin LLM"
    subtitle="Find answers to common questions about Moxin LLM's capabilities, openness, and how to get involved."
    tagline="Moxin LLM FAQs"
    classes={{ container: 'max-w-6xl' }}
    items={[
      {
        title: 'What makes Moxin LLM "truly open"?',
        description:
          "Moxin LLM provides not only model weights but also detailed training data composition and scripts, allowing for complete reproducibility and deep customization.",
      },
      {
        title: 'What are the key technical advantages of Moxin LLM?',
        description:
          'Moxin LLM utilizes GPRO enhanced learning and a Tokenizer MOE architecture, contributing to its SOTA-level performance and efficiency, especially on edge devices.',
      },
      {
        title: 'How can I run Moxin LLM on edge devices?',
        description:
          "Moxin LLM is designed for edge AI and can be efficiently run using the OminiX inference and fine-tuning engine, which is optimized for various hardware including NPUs.",
      },
      {
        title: 'What kind of applications can I build with Moxin LLM?',
        description:
          "Its customizability makes it suitable for a range of applications, including robotics, professional translation, on-device intelligent assistants, and local knowledge base applications.",
      },
      {
        title: 'How can I contribute to the Moxin LLM project?',
        description:
          "We welcome contributions! You can contribute to model optimization, develop new use cases, improve documentation, or help build the OminiX engine. Join our GitHub and Discord communities to learn more.",
      },
      {
        title: 'Where can I find the Moxin LLM models and resources?',
        description:
          "Models are available on Hugging Face (moxin-org), and you can find code, technical reports, and more on our GitHub repository (moxin-org/Moxin-LLM).",
      },
    ]}
  />

  <Stats
    stats={[
      { title: 'Hugging Face Downloads', amount: '2K+' }, 
      { title: 'GitHub Stars', amount: '124+' }, 
      { title: 'Active Models', amount: '4+' }, 
      { title: 'Community Members', amount: 'Growing' },
    ]}
  />

  <CallToAction
    actions={[
      {
        variant: 'primary',
        text: 'Join Moxin\'s Discord',
        href: 'https://discord.gg/dawBjMrsSD', 
        target: '_blank',
        icon: 'tabler:brand-discord', 
      },
    ]}
  >
    <Fragment slot="title">
      Join the Moxin LLM <br class="block sm:hidden" /><span class="sm:whitespace-nowrap">Community</span>
    </Fragment>

    <Fragment slot="subtitle">
     Become part of a movement towards truly open, reproducible, and high-performance AI. <br class="hidden md:inline" />Start building and contributing today!
    </Fragment>
  </CallToAction>
</Layout>